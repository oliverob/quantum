{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qgan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOX4sjMKPZJM1QBJQSL21l1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverob/quantum/blob/master/qgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldLDoEjQtx8g",
        "colab_type": "text"
      },
      "source": [
        "# Quantum Generative Adversarial Network (qGAN)\n",
        "\n",
        "Loading an arbitary random probability distribution into a n qubit quantum state normally requires $O(2^n)$ gates which in most algorithms will dominate the complexity of the quantum algorithm and make it useless. By using a qGAN this loading can be done in $O(poly(n))$ gates [[1](https://https://www.nature.com/articles/s41534-019-0223-2)]. \n",
        "\n",
        "A qGAN is a version of a [Generative Adversarial Network](https://papers.nips.cc/paper/5423-generative-adversarial-nets) with a quantum generator and a classical discriminator. The quantum generator is trained to transform a given n-qubit input into:\n",
        "$$\n",
        "\\sum_{j=0}^{2^n-1} \\sqrt{p^j_{\\theta}}\\left| j \\right\\rangle\n",
        "$$\n",
        "where $p^j_{\\theta}$ relate to the probabilty of the state $j$. The discriminator has to try and distinguish between the output of the generator and the training data set. The two networks train alternatively and will eventaully reach a nash equilibrium where the discriminator cannot tell apart the generator and the training set data. The aim of this process is for $p^j_{\\theta}$ to approximate the distribution of the training data.\n",
        "\n",
        "This tutorial will guide you through using a qGAN to load a lognormal distribution to a 2 qubit system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwQzoKsCuSrY",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4g8Xz0auW9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.1.0  tensorflow-quantum tensorflow-gan tensorflow-probability==0.9 tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNr2dGRvtFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import tensorflow_gan as tfg\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Intialise qubits\n",
        "num_qubits = 2 #@param\n",
        "qubits = [cirq.GridQubit(x,0) for x in range(num_qubits)]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn7A2fP1KnQL",
        "colab_type": "text"
      },
      "source": [
        "# Load Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoK9Y-NKxSV",
        "colab_type": "text"
      },
      "source": [
        "Before building the model, you need to generate the training data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3G6JxNOQe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data():\n",
        "  \"\"\"Generate training data for discriminator\n",
        "     \n",
        "     Bundles this with noise for generator to use\n",
        "  \"\"\"\n",
        "\n",
        "  size = 1000 # Size of training data set\n",
        "\n",
        "  # Take samples of lognormal distribution with mean = 1 and standard deviation =1\n",
        "  mu =1\n",
        "  sigma =1\n",
        "  continous_data = np.random.lognormal(mean=mu, sigma=sigma, size=size)\n",
        "  \n",
        "  # Remove all samples that lie outside the range expressible in the given number of qubits\n",
        "  continous_data = continous_data[continous_data <= 2**num_qubits-0.5]\n",
        "\n",
        "  # Discretize the remaining samples so the continous distribution can be approximated by a discrete distribution\n",
        "  discrete_data = tf.convert_to_tensor(np.digitize(continous_data,[i - 0.5 for i in range(1,2**num_qubits)]),dtype=tf.dtypes.int32)\n",
        "\n",
        "  # Convert the decimal into binary tensor\n",
        "  discrete_data = tf.cast(tf.math.mod(tf.bitwise.right_shift(tf.expand_dims(discrete_data,1), tf.range(num_qubits)), 2),dtype=tf.float32)\n",
        "  \n",
        "  # Intialise the same number of circuits as the discrete tensor to a uniform distribution by applying multiple hardardman gates\n",
        "  noise = []\n",
        "  for n in range(discrete_data.shape[0]):\n",
        "      noise.append(cirq.Circuit(cirq.Moment(cirq.H.on_each(qubits))))\n",
        "  noise = tfq.convert_to_tensor(noise)\n",
        "\n",
        "  return noise, discrete_data\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGhG-BIAVmCW",
        "colab_type": "text"
      },
      "source": [
        "# Quantum Generator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8nF0dBAelvH",
        "colab_type": "text"
      },
      "source": [
        "Each layer of a quantum generator consists of a layer of parameterised $R_y$ rotations, and a layer of $CZ$ gates to entangle all the qubits.\n",
        "\n",
        "The quantum generator you will be using only is only one layer deep. To represent more complex structures a larger circuit depth would need to be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kVGCmeaV7nQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "98b4f238-d6a3-4513-c35f-66136974074d"
      },
      "source": [
        "def quantum_generator_model(initial_distribution_tensor):\n",
        "  # Create parameters for each qubit\n",
        "  theta = sympy.symbols('a0:%d'%num_qubits)\n",
        "\n",
        "  # Set the input to the network\n",
        "  inputs = tf.keras.Input(shape=(),dtype=tf.dtypes.string)\n",
        "\n",
        "  # Create the parameterised Ry rotation layer circuit\n",
        "  parameterized_circuit = cirq.Circuit(cirq.Moment([cirq.ry(theta[i])(qubits[i]) for i in range(num_qubits)]))\n",
        "\n",
        "  # Entangle all the qubits by applying CZ in a circular fashion - except when there are only two qubits and then just apply one CZ\n",
        "  entangle_circuit = cirq.Circuit()\n",
        "  if(num_qubits > 2):\n",
        "    for i in range(num_qubits):\n",
        "      entangle_circuit.append([cirq.CZ(qubits[i], qubits[(i + 1) % num_qubits])])\n",
        "  else:\n",
        "    entangle_circuit.append([cirq.CZ(qubits[0],qubits[1])])\n",
        "  \n",
        "  # Combine the parameterized circuit layer and the entanglement circuit layer\n",
        "  layer_circuit =  parameterized_circuit + entangle_circuit\n",
        "  print(layer_circuit)\n",
        "\n",
        "  # Add this circuit layer to the network with an output on measurements on in the Z component\n",
        "  # Manipulate the output so it maps the -1, 1 outputs to 0, 1 like the binary discrete data generated by generate_data\n",
        "  layer = tfq.layers.PQC(layer_circuit, [(cirq.Z(qubits[i])+1)/2 for i in range(num_qubits)], repetitions=1)(inputs) #Important to have repetition =1\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[layer])\n",
        "\n",
        "  #model.summary()\n",
        "\n",
        "  return model(initial_distribution_tensor)\n",
        "\n",
        "# Test the quantum generator\n",
        "noise, real_data = generate_data()\n",
        "print(quantum_generator_model(noise))\n",
        "print(real_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 0): ───Ry(a0)───@───────@───\n",
            "                    │       │\n",
            "(1, 0): ───Ry(a1)───@───@───┼───\n",
            "                        │   │\n",
            "(2, 0): ───Ry(a2)───────@───@───\n",
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]], shape=(856, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 1. 0.]], shape=(856, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfzqbvDmR1m1",
        "colab_type": "text"
      },
      "source": [
        "## Generator Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IgRsGmCR43s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss_function(gan_model):\n",
        "  # Function from https://www.nature.com/articles/s41534-019-0223-2\n",
        "  m = gan_model.discriminator_gen_outputs.shape[0]\n",
        "  sum = tf.math.reduce_sum(tf.math.log(gan_model.discriminator_gen_outputs))\n",
        "  sum = 1/m * sum\n",
        "  return sum"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Sh5UwR40fg",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NQcpLm1KCCa",
        "colab_type": "text"
      },
      "source": [
        "The discriminator is a classical neural network. You will use a 3-layer network with 50 input nodes, 20 hidden nodes and 1 output nodes. The structure of the discriminator is picked so it is equally balanced with the generator by emperical methods (we have just used the same structure as https://www.nature.com/articles/s41534-019-0223-2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHHwHieb7QLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model(real_input, gen_inputs):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(num_qubits,)))\n",
        "  model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(20, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "  #model.summary()\n",
        "  #print(real_input)\n",
        "  \n",
        "  return model(real_input)\n",
        "\n",
        "#discriminator = make_discriminator_model()\n",
        "#tf.keras.utils.plot_model(discriminator,show_shapes=True, show_layer_names=False, dpi=70)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2lrCLuLMfFc",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezQQLtBGMn2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss_function(gan_model):\n",
        "  # function from https://www.nature.com/articles/s41534-019-0223-2\n",
        "  m = gan_model.discriminator_gen_outputs.shape[0]\n",
        "  sum = tf.math.reduce_sum(tf.math.log(gan_model.discriminator_real_outputs) + tf.math.log(1-gan_model.discriminator_gen_outputs))\n",
        "  sum = 1/m * sum\n",
        "  return sum"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF4uYrrbLx-Z",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNHvJtnEL2sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_eval_metric_ops_fn(gan_model):\n",
        "  real_data_logits = tf.reduce_mean(gan_model.discriminator_real_outputs)\n",
        "  gen_data_logits = tf.reduce_mean(gan_model.discriminator_gen_outputs)\n",
        "\n",
        "  # Convert 2 bit binary tensor into single decimal tensor\n",
        "  sum_tensor = tf.reduce_sum(tf.map_fn(lambda t: t * 2 ** tf.range(tf.cast(gan_model.generated_data.shape[1], dtype=tf.int64)),\n",
        "    tf.cast(tf.reverse(tensor=gan_model.generated_data, axis=[1]), dtype=tf.int64)), axis=1)\n",
        "  \n",
        "  # Create labels to compare sum_tensor to so we can return the percentage of each result at every evaluation\n",
        "  zeros = tf.zeros(sum_tensor.shape)\n",
        "  ones = tf.ones(sum_tensor.shape)\n",
        "  twos = tf.ones(sum_tensor.shape) * 2\n",
        "  threes = tf.ones(sum_tensor.shape) * 3\n",
        "\n",
        "  # Attempt to calculate entropy to see how accurate the network is (but this doesn't work yet - just gives nan)\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "  entropy = cce(gan_model.generated_data, gan_model.real_data)\n",
        "  return {\n",
        "      'real_data_logits': tf.compat.v1.metrics.mean(real_data_logits),\n",
        "      'gen_data_logits': tf.compat.v1.metrics.mean(gen_data_logits),\n",
        "      'zeros': tf.compat.v1.metrics.accuracy(zeros,sum_tensor),\n",
        "      'ones':tf.compat.v1.metrics.accuracy(ones,sum_tensor),\n",
        "      'twos':tf.compat.v1.metrics.accuracy(twos,sum_tensor),\n",
        "      'threes':tf.compat.v1.metrics.accuracy(threes,sum_tensor),\n",
        "      'entropy':tf.compat.v1.metrics.mean(entropy),\n",
        "  }"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L82bU_YpLm-m",
        "colab_type": "text"
      },
      "source": [
        "# GANEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayp5JoOqLrXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc38a488-2ac6-4daa-fbf4-7ff2fd4b784c"
      },
      "source": [
        "generator_lr = 0.001\n",
        "discriminator_lr = 0.0002\n",
        "\n",
        "# Configure the GAN estimator with all the functions from above\n",
        "gan_estimator = tfg.estimator.GANEstimator(generator_fn=quantum_generator_model,\n",
        "                           discriminator_fn=discriminator_model,\n",
        "                           generator_loss_fn=generator_loss_function,\n",
        "                           discriminator_loss_fn=discriminator_loss_function,\n",
        "                           generator_optimizer=tf.compat.v1.train.AdamOptimizer(generator_lr, 0.5),\n",
        "                           discriminator_optimizer=tf.compat.v1.train.AdamOptimizer(discriminator_lr, 0.5),\n",
        "                           get_eval_metric_ops_fn=get_eval_metric_ops_fn)\n",
        "\n",
        "steps_per_eval = 10 #@param\n",
        "max_train_steps = 100 #@param\n",
        "batches_for_eval_metrics = 10 #@param\n",
        "\n",
        "# Used to track metrics.\n",
        "steps = []\n",
        "real_logits, fake_logits = [], []\n",
        "zeros, ones, twos, threes = [],[],[],[]\n",
        "\n",
        "cur_step = 0\n",
        "start_time = time.time()\n",
        "while cur_step < max_train_steps:\n",
        "  next_step = min(cur_step + steps_per_eval, max_train_steps)\n",
        "  gan_estimator.train(generate_data, max_steps=next_step)\n",
        "  steps_taken = next_step - cur_step\n",
        "  cur_step = next_step\n",
        "  \n",
        "  # Calculate some metrics.\n",
        "  metrics = gan_estimator.evaluate(generate_data, steps=batches_for_eval_metrics)\n",
        "  steps.append(cur_step)\n",
        "  real_logits.append(metrics['real_data_logits'])\n",
        "  fake_logits.append(metrics['gen_data_logits'])\n",
        "  print('Average discriminator output on Real: %.2f  Fake: %.2f' % (\n",
        "      real_logits[-1], fake_logits[-1]))\n",
        "  plt.figure()\n",
        "  plt.bar(np.arange(0,4), [metrics['zeros'],metrics['ones'],metrics['twos'],metrics['threes']])\n",
        "  zeros.append(metrics['zeros'])\n",
        "  ones.append(metrics['ones'])\n",
        "  twos.append(metrics['twos'])\n",
        "  threes.append(metrics['threes'])\n",
        "  print(metrics['entropy'])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(steps, zeros, steps, ones, steps, twos, steps, threes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjlrkso7q\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjlrkso7q', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function GANEstimator.__init__.<locals>._model_fn at 0x7fae7b7432f0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.321094, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 10 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.3661062.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:49:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-10\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.92984s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:49:53\n",
            "INFO:tensorflow:Saving dict for global step 10: discriminator_loss = -1.3667452, entropy = nan, gen_data_logits = 0.511203, generator_loss = -0.6710436, global_step = 10, loss = -1.3667452, ones = 0.0053333333, real_data_logits = 0.5217606, threes = 0.55733335, twos = 0.4335, zeros = 0.0038333333\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: /tmp/tmpjlrkso7q/model.ckpt-10\n",
            "Average discriminator output on Real: 0.52  Fake: 0.51\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-10\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 10 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.3706237, step = 10\n",
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.4174153.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:49:59Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-20\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.99218s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:00\n",
            "INFO:tensorflow:Saving dict for global step 20: discriminator_loss = -1.4193214, entropy = nan, gen_data_logits = 0.524186, generator_loss = -0.64598644, global_step = 20, loss = -1.4193214, ones = 0.0059322035, real_data_logits = 0.50851995, threes = 0.5622034, twos = 0.42762712, zeros = 0.004237288\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: /tmp/tmpjlrkso7q/model.ckpt-20\n",
            "Average discriminator output on Real: 0.51  Fake: 0.52\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-20\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.42323, step = 20\n",
            "INFO:tensorflow:Saving checkpoints for 30 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.4711331.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:06Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-30\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.96922s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:07\n",
            "INFO:tensorflow:Saving dict for global step 30: discriminator_loss = -1.4720995, entropy = nan, gen_data_logits = 0.537337, generator_loss = -0.62125856, global_step = 30, loss = -1.4720995, ones = 0.0067357514, real_data_logits = 0.49611425, threes = 0.5580311, twos = 0.4300518, zeros = 0.005181347\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30: /tmp/tmpjlrkso7q/model.ckpt-30\n",
            "Average discriminator output on Real: 0.50  Fake: 0.54\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-30\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 30 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.4787662, step = 30\n",
            "INFO:tensorflow:Saving checkpoints for 40 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.525995.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:13Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-40\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.97511s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:14\n",
            "INFO:tensorflow:Saving dict for global step 40: discriminator_loss = -1.5259699, entropy = nan, gen_data_logits = 0.5501564, generator_loss = -0.5977688, global_step = 40, loss = -1.5259699, ones = 0.008373591, real_data_logits = 0.48356724, threes = 0.55152977, twos = 0.4347826, zeros = 0.0053140097\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40: /tmp/tmpjlrkso7q/model.ckpt-40\n",
            "Average discriminator output on Real: 0.48  Fake: 0.55\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-40\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 40 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.5313491, step = 40\n",
            "INFO:tensorflow:Saving checkpoints for 50 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.5814705.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-50\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.96375s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:21\n",
            "INFO:tensorflow:Saving dict for global step 50: discriminator_loss = -1.5813547, entropy = nan, gen_data_logits = 0.56256807, generator_loss = -0.57556635, global_step = 50, loss = -1.5813547, ones = 0.007894737, real_data_logits = 0.4706164, threes = 0.53125, twos = 0.45427632, zeros = 0.0065789474\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /tmp/tmpjlrkso7q/model.ckpt-50\n",
            "Average discriminator output on Real: 0.47  Fake: 0.56\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-50\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 50 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.5888276, step = 50\n",
            "INFO:tensorflow:Saving checkpoints for 60 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.6451112.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:27Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-60\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.96454s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:28\n",
            "INFO:tensorflow:Saving dict for global step 60: discriminator_loss = -1.6422592, entropy = nan, gen_data_logits = 0.57580954, generator_loss = -0.55242676, global_step = 60, loss = -1.6422592, ones = 0.0072847684, real_data_logits = 0.45681602, threes = 0.535596, twos = 0.452649, zeros = 0.004470199\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 60: /tmp/tmpjlrkso7q/model.ckpt-60\n",
            "Average discriminator output on Real: 0.46  Fake: 0.58\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-60\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 60 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.6509174, step = 60\n",
            "INFO:tensorflow:Saving checkpoints for 70 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.709187.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-70\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 1.00544s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:34\n",
            "INFO:tensorflow:Saving dict for global step 70: discriminator_loss = -1.7091427, entropy = nan, gen_data_logits = 0.59141445, generator_loss = -0.52594554, global_step = 70, loss = -1.7091427, ones = 0.00928, real_data_logits = 0.44395787, threes = 0.5432, twos = 0.4392, zeros = 0.00832\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 70: /tmp/tmpjlrkso7q/model.ckpt-70\n",
            "Average discriminator output on Real: 0.44  Fake: 0.59\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-70\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 70 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.7174889, step = 70\n",
            "INFO:tensorflow:Saving checkpoints for 80 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.790208.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-80\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.98008s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:41\n",
            "INFO:tensorflow:Saving dict for global step 80: discriminator_loss = -1.7832139, entropy = nan, gen_data_logits = 0.60673684, generator_loss = -0.50064135, global_step = 80, loss = -1.7832139, ones = 0.008952702, real_data_logits = 0.4287591, threes = 0.51317567, twos = 0.46976352, zeros = 0.008108108\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80: /tmp/tmpjlrkso7q/model.ckpt-80\n",
            "Average discriminator output on Real: 0.43  Fake: 0.61\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-80\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 80 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.7944455, step = 80\n",
            "INFO:tensorflow:Saving checkpoints for 90 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.8660104.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:47Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-90\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 1.00737s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:48\n",
            "INFO:tensorflow:Saving dict for global step 90: discriminator_loss = -1.8626773, entropy = nan, gen_data_logits = 0.6255778, generator_loss = -0.47029623, global_step = 90, loss = -1.8626773, ones = 0.009298532, real_data_logits = 0.4165743, threes = 0.50522023, twos = 0.47553018, zeros = 0.009951061\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 90: /tmp/tmpjlrkso7q/model.ckpt-90\n",
            "Average discriminator output on Real: 0.42  Fake: 0.63\n",
            "nan\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function parse_programs at 0x7fae97993840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-90\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 90 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:loss = -1.8747579, step = 90\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpjlrkso7q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: -1.9657041.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(0, 0): ───Ry(a0)───@───\n",
            "                    │\n",
            "(1, 0): ───Ry(a1)───@───\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T09:50:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjlrkso7q/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.95951s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-09:50:55\n",
            "INFO:tensorflow:Saving dict for global step 100: discriminator_loss = -1.9677017, entropy = nan, gen_data_logits = 0.6510126, generator_loss = -0.43074673, global_step = 100, loss = -1.9677017, ones = 0.010296412, real_data_logits = 0.4033714, threes = 0.50031203, twos = 0.4778471, zeros = 0.011544461\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpjlrkso7q/model.ckpt-100\n",
            "Average discriminator output on Real: 0.40  Fake: 0.65\n",
            "nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fae77f0b048>,\n",
              " <matplotlib.lines.Line2D at 0x7fae77f0b198>,\n",
              " <matplotlib.lines.Line2D at 0x7fae77f0b2e8>,\n",
              " <matplotlib.lines.Line2D at 0x7fae77f0b438>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}